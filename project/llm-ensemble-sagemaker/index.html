<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>LLM Ensemble on SageMaker · Jayeetra Bhattacharjee</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Production-grade LLM ensemble deployed on AWS SageMaker, achieving 90-95% accuracy across multiple models.">
  <style>
    :root {
      --bg: #020617;
      --surface: #020617;
      --border-soft: rgba(148,163,184,0.35);
      --border-strong: rgba(148,163,184,0.55);
      --accent: #38bdf8;
      --accent-soft: rgba(56,189,248,0.12);
      --text-main: #e5e7eb;
      --text-soft: #9ca3af;
      --text-faint: #6b7280;
      --radius-lg: 24px;
      --radius-md: 18px;
      --radius-pill: 999px;
      --shadow-soft: 0 18px 40px rgba(15,23,42,0.9);
    }
    * { box-sizing: border-box; margin: 0; padding: 0; }
    body {
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "SF Pro Text", "Segoe UI", sans-serif;
      background: radial-gradient(circle at top, #020617 0, #000 60%) fixed;
      color: var(--text-main);
      min-height: 100vh;
      padding: 24px 16px 40px;
      -webkit-font-smoothing: antialiased;
    }
    .page-shell {
      max-width: 960px;
      margin: 0 auto;
      background: linear-gradient(145deg, rgba(15,23,42,0.98), rgba(15,23,42,0.96));
      border-radius: var(--radius-lg);
      border: 1px solid rgba(148,163,184,0.4);
      box-shadow: var(--shadow-soft);
      padding: 20px 22px 26px;
    }
    @media (max-width: 768px) { .page-shell { padding: 16px 14px 22px; } }
    .top-nav {
      display: flex;
      justify-content: space-between;
      align-items: center;
      gap: 14px;
      margin-bottom: 20px;
    }
    .logo {
      font-size: 13px;
      letter-spacing: 0.16em;
      text-transform: uppercase;
      color: var(--text-soft);
      text-decoration: none;
    }
    .logo strong { color: var(--text-main); }
    nav a {
      font-size: 11px;
      letter-spacing: 0.14em;
      text-transform: uppercase;
      color: var(--text-soft);
      text-decoration: none;
      margin-left: 14px;
      white-space: nowrap;
    }
    nav a:first-of-type { margin-left: 0; }
    nav a:hover { color: var(--accent); }
    @media (max-width: 720px) {
      .top-nav { flex-direction: column; align-items: flex-start; }
      nav { display: flex; flex-wrap: wrap; gap: 10px; }
      nav a { margin-left: 0; }
    }
    .hero { margin-bottom: 18px; }
    .category {
      font-size: 11px;
      letter-spacing: 0.16em;
      text-transform: uppercase;
      color: var(--accent);
      margin-bottom: 6px;
    }
    h1 { font-size: 24px; margin-bottom: 8px; }
    .meta-line {
      display: flex;
      flex-wrap: wrap;
      gap: 10px;
      font-size: 11px;
      color: var(--text-faint);
      margin-bottom: 8px;
    }
    .subtitle {
      font-size: 13px;
      color: var(--text-soft);
      max-width: 40rem;
    }
    .layout {
      display: grid;
      grid-template-columns: minmax(0, 2.3fr) minmax(0, 1.7fr);
      gap: 16px;
      margin-top: 18px;
    }
    @media (max-width: 840px) { .layout { grid-template-columns: minmax(0, 1fr); } }
    section {
      border-radius: var(--radius-md);
      border: 1px solid var(--border-soft);
      background: rgba(15,23,42,0.97);
      padding: 14px 14px 16px;
      box-shadow: 0 12px 30px rgba(15,23,42,0.9);
    }
    .section-title { font-size: 14px; margin-bottom: 6px; }
    p {
      font-size: 13px;
      color: var(--text-soft);
      line-height: 1.6;
      margin-bottom: 8px;
    }
    ul {
      list-style: none;
      font-size: 13px;
      color: var(--text-soft);
    }
    li + li { margin-top: 4px; }
    .impact-list li::before {
      content: "•";
      margin-right: 6px;
      color: var(--accent);
    }
    .side-block {
      margin-bottom: 10px;
      font-size: 13px;
      color: var(--text-soft);
    }
    .side-block h2 { font-size: 13px; margin-bottom: 4px; }
    .tag-cloud {
      display: flex;
      flex-wrap: wrap;
      gap: 6px;
      margin-top: 4px;
      font-size: 11px;
    }
    .tag {
      padding: 3px 8px;
      border-radius: var(--radius-pill);
      border: 1px solid rgba(51,65,85,0.9);
      background: #020617;
      color: var(--text-faint);
    }
    .back-link { margin-top: 16px; font-size: 12px; }
    a { color: var(--accent); text-decoration: none; }
    a:hover { text-decoration: underline; }
    footer { margin-top: 16px; font-size: 11px; color: var(--text-faint); text-align: right; }
  </style>
</head>
<body>
  <div class="page-shell">
    <header class="top-nav">
      <a href="/" class="logo"><strong>Jayeetra Bhattacharjee</strong> · AI & Analytics</a>
      <nav>
        <a href="/">Projects</a>
        <a href="/experience.html">Experience</a>
        <a href="/about.html">About</a>
        <a href="/contact.html">Contact</a>
      </nav>
    </header>

    <main>
      <section class="hero">
        <p class="category">LLM · Ensemble · AWS SageMaker</p>
        <h1>LLM Ensemble on SageMaker</h1>
        <div class="meta-line">
          <span>Client: Global enterprise</span>
          <span>Year: 2024</span>
          <span>Role: ML Engineer</span>
        </div>
        <p class="subtitle">
          Production‑grade ensemble combining GPT‑4, Gemini, Claude, and open‑source models with ranking
          and evaluation pipeline deployed on AWS SageMaker, achieving 90–95% accuracy and maintaining
          operational reliability for enterprise use.
        </p>
      </section>

      <div class="layout">
        <section>
          <h2 class="section-title">Context</h2>
          <p>
            Relying on a single LLM introduces risk: model-specific failures, hallucinations, and drift.
            The client needed a production system that combined multiple LLM strengths, evaluated outputs
            in real‑time, and surfaced only the most reliable predictions for critical business decisions.
          </p>

          <h2 class="section-title">Approach</h2>
          <p>
            I designed a multi‑model ensemble architecture deployed on AWS SageMaker that ingests requests,
            routes them in parallel to multiple LLM endpoints, aggregates outputs using learned ranking,
            and returns the consensus prediction with confidence scores.
          </p>
          <ul>
            <li>Set up SageMaker inference endpoints for GPT‑4, Gemini, Claude, and Hugging Face models.</li>
            <li>Implemented parallel request routing with timeout handling for fault tolerance.</li>
            <li>Developed a ranking model (gradient boosting) to weight each model's predictions based on calibration.</li>
            <li>Added real‑time evaluation metrics and model drift detection.</li>
            <li>Built logging and monitoring dashboards for operational oversight.</li>
          </ul>

          <h2 class="section-title" style="margin-top:10px;">Impact</h2>
          <ul class="impact-list">
            <li>Ensemble accuracy reached 90–95%, outperforming individual models by 5–10%.</li>
            <li>System confidence scores correlated well with actual accuracy, enabling safe filtering.</li>
            <li>Reduced hallucination rate by ~40% through consensus and ranking.</li>
            <li>Operational uptime: 99.8% despite individual model downtime (SageMaker auto‑failover).</li>
          </ul>
        </section>

        <aside>
          <div class="side-block">
            <h2>Responsibilities</h2>
            <p>
              End‑to‑end deployment: SageMaker setup, model endpoint configuration, ensemble architecture,
              ranking model development, monitoring pipelines, and production support.
            </p>
          </div>

          <div class="side-block">
            <h2>Technologies</h2>
            <div class="tag-cloud">
              <span class="tag">AWS SageMaker</span>
              <span class="tag">GPT‑4 / Gemini / Claude</span>
              <span class="tag">Python</span>
              <span class="tag">XGBoost</span>
              <span class="tag">CloudWatch</span>
              <span class="tag">Docker</span>
            </div>
          </div>

          <div class="side-block">
            <h2>What this illustrates</h2>
            <p>
              How to architect production LLM systems that balance accuracy, reliability, and scalability
              by combining multiple models and leveraging cloud infrastructure for operational resilience.
            </p>
          </div>
        </aside>
      </div>

      <div class="back-link">
        ← <a href="/">Back to all projects</a>
      </div>
    </main>

    <footer>
      Interested in production LLM systems? Contact: <a href="mailto:jayeetra.uk@gmail.com">jayeetra.uk@gmail.com</a>
    </footer>
  </div>
</body>
</html>
